{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from memory import Memory\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Fill:0' shape=(2, 10, 5) dtype=float32>,\n",
       " <tf.Tensor 'Fill_1:0' shape=(2, 10) dtype=float32>,\n",
       " <tf.Tensor 'Fill_2:0' shape=(2, 10, 1) dtype=float32>,\n",
       " <tf.Tensor 'Fill_3:0' shape=(2, 5, 1) dtype=float32>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "read_heads = 1\n",
    "num_keys = 1\n",
    "\n",
    "mem_size = 10\n",
    "vector_size = 5\n",
    "\n",
    "memory = Memory(mem_size, vector_size, read_heads, batch_size)\n",
    "memory_state = memory.init_memory()\n",
    "memory_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = tf.fill([batch_size,vector_size,num_keys], 1.0)\n",
    "strengths = tf.fill([batch_size,1], 1.0)\n",
    "interpolation_gate = tf.fill([batch_size,1], 1.0)\n",
    "shift_weighting = tf.nn.softmax(tf.constant([0.2, 0.6, 0.2]) + 1e-12)\n",
    "gamma = tf.fill([batch_size,1], 1.0)\n",
    "\n",
    "add = tf.constant([2.0, 1.6, 4.0, 1.0, 0.1])\n",
    "erase = tf.constant([0.0, 0.0, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get content addressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transpose_1:0\", shape=(2, 10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "normalized_memory = tf.nn.l2_normalize(memory_state[0], 2)\n",
    "normalized_keys = tf.nn.l2_normalize(keys, 1)\n",
    "\n",
    "similiarity = tf.batch_matmul(normalized_memory, normalized_keys)\n",
    "\n",
    "strengths = tf.expand_dims(strengths, 1)\n",
    "\n",
    "content_weights = tf.nn.softmax(similiarity * strengths, 1)\n",
    "print(content_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(2, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "content_weights = tf.squeeze(content_weights,axis=2)\n",
    "gated_weighting = interpolation_gate * content_weights + (1 - interpolation_gate) * memory_state[1]\n",
    "print(gated_weighting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circular convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims_2:0' shape=(2, 10, 1) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(gated_weighting,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 1)\n",
      "Tensor(\"DynamicStitch_2:0\", shape=(?, 3), dtype=float32)\n",
      "[<tf.Tensor 'Sum_4:0' shape=(3,) dtype=float32>, <tf.Tensor 'Sum_5:0' shape=(3,) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "size = int(gated_weighting.get_shape()[0])\n",
    "kernel_size = int(shift_weighting.get_shape()[0])\n",
    "kernel_shift = int(math.floor(kernel_size/2.0))\n",
    "\n",
    "print(size,kernel_size,kernel_shift)\n",
    "\n",
    "def loop(idx):\n",
    "    if idx < 0: return size + idx\n",
    "    if idx >= size : return idx - size\n",
    "    else: return idx\n",
    "\n",
    "kernels = []\n",
    "for i in xrange(size):\n",
    "    indices = [loop(i+j) for j in xrange(kernel_shift, -kernel_shift-1, -1)]\n",
    "    temp = tf.transpose(gated_weighting)\n",
    "    v_ = tf.transpose(tf.gather(temp, indices))\n",
    "    kernels.append(tf.reduce_sum(v_ * shift_weighting, 0))\n",
    "\n",
    "result_after_shift = tf.dynamic_stitch([i for i in xrange(size)], kernels)\n",
    "print(result_after_shift)\n",
    "print(kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05727664  0.08544672  0.05727664]\n",
      " [ 0.05727664  0.08544672  0.05727664]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    values = session.run(result_after_shift)\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_weigth, new_memory = memory.write(memory_state[0],memory_state[1],keys,strengths,interpolation_gate,shift_weighting,gamma,add,erase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
